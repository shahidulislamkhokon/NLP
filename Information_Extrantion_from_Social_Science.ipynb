{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOeImCYtnB0sgiIRhJJX7k/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahidulislamkhokon/NLP/blob/main/Information_Extrantion_from_Social_Science.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Information Extraction for Social Science Research"
      ],
      "metadata": {
        "id": "PF3rCEvvV9eP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "installing spaCy and other dependencies for this project"
      ],
      "metadata": {
        "id": "yzDc7NUUWKAu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXOsHE4eUg7l"
      },
      "outputs": [],
      "source": [
        "!nvcc --version\n",
        "!pip install --upgrade spacy\n",
        "!pip install --upgrade spacy[cuda111,transformers]\n",
        "!pip install jsonlines\n",
        "!python -m spacy download en_core_web_lg\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "!wget https://andrewhalterman.com/files/cleaned_masdar.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am going to use two techniques for information extraction: named entity recognition and rule-based extraction using dependency parses. The plan is to:\n",
        "\n",
        "- get started with some hands-on named entity recognition\n",
        "- step back and discuss information extraction and structured prediction at a higher level\n",
        "- return to NER with some applications on real text\n",
        "- next, use dependency parses and custom rules as a technique for information extraction\n",
        "- conclude with some thoughts about extentions"
      ],
      "metadata": {
        "id": "z-7JpSR9XmRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting started with **NER** and **spaCy**"
      ],
      "metadata": {
        "id": "PfAJnYIBYTPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jsonlines\n",
        "\n",
        "from tqdm.autonotebook import tqdm\n",
        "import jsonlines\n",
        "import re\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "# assert spacy.__version__ == \"3.1.3\""
      ],
      "metadata": {
        "id": "4R306_IEWkgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For spacy I need a pretrain model for prcessing document.\n",
        "- large model (pre-train model with more example)\n",
        "- small model (without pre-train word embedding)\n",
        "- trf model (transformer-based model)\n",
        "I am using large model (en_core_web_trf) and also small model(en_core_web_sm) for comparision"
      ],
      "metadata": {
        "id": "bkKZY2uacYu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "nlp_sm = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "d5lpjvn8d2vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, I'll load in a collection of news stories from a local **pro-government newspaper** in **Syri**a called al-Masdar. The articles here primarily describe the **civil war in Syria in 2016 and 2017**"
      ],
      "metadata": {
        "id": "oxgc9XZReBN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with jsonlines.open(\"cleaned_masdar.jsonl\", \"r\") as f:\n",
        "    articles = list(f.iter())\n",
        "print(articles)\n",
        "print(len(articles))"
      ],
      "metadata": {
        "id": "W1EBaP4EeCQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article = articles[500]\n",
        "article"
      ],
      "metadata": {
        "id": "eJyYcEjLemse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To process a document with **spaCy**, I'll use the **nlp object** we instatiated earlier and pass a piece of text to it. The **nlp object** returns a **Document class object**, which has both document and token-level attributes."
      ],
      "metadata": {
        "id": "uU44BmXXfAAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(article['body'])\n",
        "\n",
        "# take a look at how many words in a document\n",
        "len(doc)"
      ],
      "metadata": {
        "id": "us7Ypj6ufKKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look document-level attributes\n",
        "dir(doc)"
      ],
      "metadata": {
        "id": "fsNdI6bNfVJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokens in a document can by accessed by their number:\n",
        "print(doc[5])\n",
        "dir(doc[5])"
      ],
      "metadata": {
        "id": "v9TJvajHfcp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the attributes it assigns is **named entity** information for the document. Using **spaCy's built-in visualizer**, we can see all the detected named entities in the document."
      ],
      "metadata": {
        "id": "lzyja1V7fleu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "id": "jxZgjR5sfmI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "just_text = [i['body'] for i in articles]\n",
        "docs = list(tqdm(nlp.pipe(just_text), total=len(just_text)))\n",
        "print(docs)"
      ],
      "metadata": {
        "id": "rW4nlDRD127d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Information Extraction and Structured Prediction"
      ],
      "metadata": {
        "id": "cbpC3B1h59r5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in doc[0:]:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "ww-FMR0B8AiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "[(i.text, i.ent_iob_ + \"-\" + i.ent_type_) for i in doc[0:30]]\n"
      ],
      "metadata": {
        "id": "QTWR_4Yk5_i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models for NER"
      ],
      "metadata": {
        "id": "jJkXT7iZHlta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's identify which organization are mentioned most in our corpus"
      ],
      "metadata": {
        "id": "7c6zfw2KSc2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "all_orgs = []\n",
        "for d in docs:\n",
        "    orgs = [ent.text for ent in d.ents if ent.label_ == \"ORG\"]\n",
        "    all_orgs.extend(orgs)\n",
        "\n",
        "Counter(all_orgs).most_common(15)"
      ],
      "metadata": {
        "id": "PRMrB7aQHmyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which organizations are mentioned most alongside mentions of \"ceasefires\" or \"negotiations\"?"
      ],
      "metadata": {
        "id": "2bAMSof9TOfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \n",
        "negotiation_orgs = []\n",
        "for d in docs:\n",
        "    for ent in d.ents:\n",
        "        if ent.label_ != \"ORG\":\n",
        "            continue\n",
        "        if re.search(\"negotiat|ceasefire|talks\", ent.sent.text):\n",
        "            negotiation_orgs.append(ent.text)\n",
        "negotiation_orgs            "
      ],
      "metadata": {
        "id": "wUp5pHB7Sdrh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}